{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install neuraloperator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zGBrbubzE3f",
        "outputId": "8718be61-118b-452a-fb60-fb33749b7e6e",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neuraloperator\n",
            "  Downloading neuraloperator-1.0.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from neuraloperator) (0.19.10)\n",
            "Collecting ruamel-yaml (from neuraloperator)\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting configmypy (from neuraloperator)\n",
            "  Downloading configmypy-0.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting tensorly (from neuraloperator)\n",
            "  Downloading tensorly-0.9.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting tensorly-torch (from neuraloperator)\n",
            "  Downloading tensorly_torch-0.5.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting torch-harmonics==0.7.3 (from neuraloperator)\n",
            "  Downloading torch_harmonics-0.7.3.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from neuraloperator) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from neuraloperator) (2.0.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from neuraloperator) (3.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from neuraloperator) (3.13.0)\n",
            "Collecting zarr (from neuraloperator)\n",
            "  Downloading zarr-3.0.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from torch-harmonics==0.7.3->neuraloperator) (2.6.0+cu124)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from configmypy->neuraloperator) (8.3.5)\n",
            "Collecting pytest-mock (from configmypy->neuraloperator)\n",
            "  Downloading pytest_mock-3.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neuraloperator) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neuraloperator) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neuraloperator) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neuraloperator) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neuraloperator) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neuraloperator) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neuraloperator) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->neuraloperator) (2.9.0.post0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel-yaml->neuraloperator)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tensorly->neuraloperator) (1.15.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb->neuraloperator) (4.13.2)\n",
            "Collecting donfig>=0.8 (from zarr->neuraloperator)\n",
            "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr->neuraloperator)\n",
            "  Downloading numcodecs-0.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->neuraloperator) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->neuraloperator) (4.0.12)\n",
            "Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr->neuraloperator)\n",
            "  Downloading crc32c-2.7.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->neuraloperator) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->neuraloperator) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->neuraloperator) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (1.3.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->configmypy->neuraloperator) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->configmypy->neuraloperator) (1.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->neuraloperator) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (3.0.2)\n",
            "Downloading neuraloperator-1.0.2-py3-none-any.whl (186 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.9/186.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading configmypy-0.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorly-0.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorly_torch-0.5.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zarr-3.0.7-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.9/203.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n",
            "Downloading numcodecs-0.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_mock-3.14.0-py3-none-any.whl (9.9 kB)\n",
            "Downloading crc32c-2.7.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-harmonics\n",
            "  Building wheel for torch-harmonics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-harmonics: filename=torch_harmonics-0.7.3-py3-none-any.whl size=87748 sha256=a1ca15ad7e6d978e0820779d4a0fad0343c0719def524f195ecdce18e003ece0\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/32/30/3f507ec7dd7ff6a24abf08cf1ea4f3271f45ef792e9fabf807\n",
            "Successfully built torch-harmonics\n",
            "Installing collected packages: ruamel.yaml.clib, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numcodecs, donfig, crc32c, tensorly-torch, tensorly, ruamel-yaml, pytest-mock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, zarr, nvidia-cusolver-cu12, configmypy, torch-harmonics, neuraloperator\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed configmypy-0.2.0 crc32c-2.7.1 donfig-0.8.1.post1 neuraloperator-1.0.2 numcodecs-0.16.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytest-mock-3.14.0 ruamel-yaml-0.18.10 ruamel.yaml.clib-0.2.12 tensorly-0.9.0 tensorly-torch-0.5.0 torch-harmonics-0.7.3 zarr-3.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "zeCuMMLsyRR0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "from neuralop.data.datasets import DarcyDataset, load_darcy_flow_small\n",
        "from neuralop.utils import count_model_params\n",
        "from neuralop.losses.data_losses import LpLoss\n",
        "from neuralop.training import Trainer\n",
        "\n",
        "device = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_pair(x_all, y_all, idx):\n",
        "    \"\"\"\n",
        "    Plot x_all[idx] and y_all[idx] side by side.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x_all : torch.Tensor or np.ndarray, shape (N, 16, 16)\n",
        "    y_all : torch.Tensor or np.ndarray, shape (N, 16, 16)\n",
        "    idx   : int, which sample to plot\n",
        "\n",
        "    Displays a matplotlib figure.\n",
        "    \"\"\"\n",
        "    # if torch.Tensor, convert to numpy\n",
        "    if hasattr(x_all, 'cpu'):\n",
        "        x = x_all[idx].cpu().numpy()\n",
        "    else:\n",
        "        x = x_all[idx]\n",
        "    if hasattr(y_all, 'cpu'):\n",
        "        y = y_all[idx].cpu().numpy()\n",
        "    else:\n",
        "        y = y_all[idx]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "    axes[0].imshow(x, aspect='equal')\n",
        "    axes[0].set_title(f'x_all[{idx}]')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(y, aspect='equal')\n",
        "    axes[1].set_title(f'y_all[{idx}]')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "K7h6E2qJZBjb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Darcy Flow Dataset"
      ],
      "metadata": {
        "id": "MWI3rO-ZV8E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = DarcyDataset(root_dir=\"./data\", n_train= 5000, n_tests= [1000, 500],\n",
        "                 batch_size = 32, test_batch_sizes = [32, 32],\n",
        "                 train_resolution= 16,\n",
        "                 test_resolutions =[16,32],download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXW2JNXi0WBM",
        "outputId": "f1d1a7a1-1dc9-46c2-e15d-b1291f29c723"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test db for resolution 16 with 1000 samples \n",
            "Loading test db for resolution 32 with 500 samples \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = ds.train_db\n",
        "full_loader = DataLoader(a,\n",
        "                         batch_size=len(a),\n",
        "                         shuffle=False,\n",
        "                         drop_last=False)\n",
        "\n",
        "batch = next(iter(full_loader))\n",
        "# batch is a dict, so:\n",
        "x_all = batch['x']        # shape [1000, 1, 16, 16]\n",
        "y_all = batch['y']\n",
        "x_all = x_all.squeeze(1)  # → [1000, 16, 16]\n",
        "y_all = y_all.squeeze(1)\n",
        "print(x_all.shape)        # should print: torch.Size([1000, 16, 16])\n",
        "print(y_all.shape)        # should print: torch.Size([1000, 16, 16])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_xG_lnsVWvs",
        "outputId": "b8b803ad-064e-4d87-c93e-b291de4e4d0d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 16, 16])\n",
            "torch.Size([1000, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = ds.test_dbs[16]\n",
        "full_loader = DataLoader(b,\n",
        "                         batch_size=len(b),\n",
        "                         shuffle=False,\n",
        "                         drop_last=False)\n",
        "\n",
        "batch = next(iter(full_loader))\n",
        "x_all_test = batch['x']\n",
        "y_all_test = batch['y']\n",
        "x_all_test = x_all_test.squeeze(1)\n",
        "y_all_test = y_all_test.squeeze(1)\n",
        "print(x_all_test.shape)        # should print: torch.Size([1000, 16, 16])\n",
        "print(y_all_test.shape)        # should print: torch.Size([1000, 16, 16])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z4McYFRUZJZ",
        "outputId": "b86decc2-c08b-4c43-b556-1eb6b117104d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 16, 16])\n",
            "torch.Size([50, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap x/y tensors in a dict-style dataset\n",
        "class DictDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x.unsqueeze(1)  # [B, 1, H, W]\n",
        "        self.y = y.unsqueeze(1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "dataset = DictDataset(x_all, y_all)"
      ],
      "metadata": {
        "id": "GgC80z9fbISK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_pair(x_all_test, y_all_test, idx=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "3ZhSvMdwVJvM",
        "outputId": "57d76ecd-47d4-488b-8594-ac0a462967ef"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_pair(x_all, y_all, idx=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "5pPqMPssVPp9",
        "outputId": "f01b0fe7-0ef8-4acb-bbf0-8436a3fbfcb8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define FNO Model"
      ],
      "metadata": {
        "id": "ui8t0M2IV403"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FNO(\n",
        "    n_modes=(12, 12),         # Fourier modes per spatial dimension\n",
        "    hidden_channels=32,       # Width of hidden layers\n",
        "    in_channels=1,            # Darcy x shape: [B, 1, H, W]\n",
        "    out_channels=1,           # Darcy y shape: [B, 1, H, W]\n",
        "    num_layers=4,             # Number of Fourier layers\n",
        "    use_mlp=True              # MLP head after FNO core\n",
        ")\n",
        "\n",
        "print(f\"Model has {count_model_params(model)} parameters.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUb-j76GWDcE",
        "outputId": "d1cd4589-9e63-4f5a-c646-f9a0b51189dc"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has 701281 parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train_fno_model(model,\n",
        "                    dataset,\n",
        "                    num_epochs=100,\n",
        "                    batch_size=32,\n",
        "                    lr=1e-3,\n",
        "                    val_split=0.1,\n",
        "                    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "    # Split dataset\n",
        "    N = len(dataset)\n",
        "    n_val = int(N * val_split)\n",
        "    n_train = N - n_val\n",
        "    train_ds, val_ds = random_split(dataset, [n_train, n_val])\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    best_val = float('inf')\n",
        "    best_state = None\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\", leave=False)\n",
        "        for i, (x, y) in enumerate(train_bar):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(x)\n",
        "            loss = criterion(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_bar.set_postfix(loss=f\"{train_loss / (i + 1):.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                pred = model(x)\n",
        "                val_loss += criterion(pred, y).item()\n",
        "        avg_val = val_loss / max(len(val_loader), 1)\n",
        "\n",
        "        print(f\"Epoch {epoch:3d} | Train Loss: {train_loss/len(train_loader):.6f} | Val Loss: {avg_val:.6f}\")\n",
        "\n",
        "        if avg_val < best_val:\n",
        "            best_val = avg_val\n",
        "            best_state = model.state_dict()\n",
        "            print(f\" → New best model (Val Loss = {best_val:.6f})\")\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    return model.to(\"cpu\")"
      ],
      "metadata": {
        "id": "jt5FJQPGZ3bl"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = train_fno_model(\n",
        "    model,\n",
        "    dataset,\n",
        "    num_epochs=100,\n",
        "    batch_size=32,\n",
        "    lr=1e-3,\n",
        "    val_split=0.1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4LG890FZ3qu",
        "outputId": "cb83d531-ae47-4083-c657-4256cdd98b71"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   1 | Train Loss: 0.158766 | Val Loss: 0.115880\n",
            " → New best model (Val Loss = 0.115880)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   2 | Train Loss: 0.083428 | Val Loss: 0.044677\n",
            " → New best model (Val Loss = 0.044677)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   3 | Train Loss: 0.027464 | Val Loss: 0.023527\n",
            " → New best model (Val Loss = 0.023527)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   4 | Train Loss: 0.020824 | Val Loss: 0.020205\n",
            " → New best model (Val Loss = 0.020205)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   5 | Train Loss: 0.018213 | Val Loss: 0.018387\n",
            " → New best model (Val Loss = 0.018387)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   6 | Train Loss: 0.015712 | Val Loss: 0.014233\n",
            " → New best model (Val Loss = 0.014233)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   7 | Train Loss: 0.012294 | Val Loss: 0.011794\n",
            " → New best model (Val Loss = 0.011794)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   8 | Train Loss: 0.010989 | Val Loss: 0.011204\n",
            " → New best model (Val Loss = 0.011204)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   9 | Train Loss: 0.009188 | Val Loss: 0.008884\n",
            " → New best model (Val Loss = 0.008884)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  10 | Train Loss: 0.007971 | Val Loss: 0.008253\n",
            " → New best model (Val Loss = 0.008253)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  11 | Train Loss: 0.006792 | Val Loss: 0.007198\n",
            " → New best model (Val Loss = 0.007198)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  12 | Train Loss: 0.006057 | Val Loss: 0.006622\n",
            " → New best model (Val Loss = 0.006622)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  13 | Train Loss: 0.005752 | Val Loss: 0.007015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  14 | Train Loss: 0.005220 | Val Loss: 0.006008\n",
            " → New best model (Val Loss = 0.006008)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  15 | Train Loss: 0.004854 | Val Loss: 0.005702\n",
            " → New best model (Val Loss = 0.005702)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  16 | Train Loss: 0.004238 | Val Loss: 0.005791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  17 | Train Loss: 0.004075 | Val Loss: 0.005445\n",
            " → New best model (Val Loss = 0.005445)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  18 | Train Loss: 0.003630 | Val Loss: 0.005116\n",
            " → New best model (Val Loss = 0.005116)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  19 | Train Loss: 0.003461 | Val Loss: 0.004859\n",
            " → New best model (Val Loss = 0.004859)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  20 | Train Loss: 0.003312 | Val Loss: 0.004996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  21 | Train Loss: 0.003395 | Val Loss: 0.004750\n",
            " → New best model (Val Loss = 0.004750)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  22 | Train Loss: 0.002977 | Val Loss: 0.004675\n",
            " → New best model (Val Loss = 0.004675)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  23 | Train Loss: 0.002553 | Val Loss: 0.004451\n",
            " → New best model (Val Loss = 0.004451)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  24 | Train Loss: 0.002479 | Val Loss: 0.004380\n",
            " → New best model (Val Loss = 0.004380)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  25 | Train Loss: 0.002280 | Val Loss: 0.004380\n",
            " → New best model (Val Loss = 0.004380)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  26 | Train Loss: 0.002165 | Val Loss: 0.004270\n",
            " → New best model (Val Loss = 0.004270)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  27 | Train Loss: 0.001989 | Val Loss: 0.004240\n",
            " → New best model (Val Loss = 0.004240)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  28 | Train Loss: 0.001992 | Val Loss: 0.004117\n",
            " → New best model (Val Loss = 0.004117)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  29 | Train Loss: 0.001954 | Val Loss: 0.004013\n",
            " → New best model (Val Loss = 0.004013)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  30 | Train Loss: 0.001828 | Val Loss: 0.003977\n",
            " → New best model (Val Loss = 0.003977)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  31 | Train Loss: 0.001747 | Val Loss: 0.003896\n",
            " → New best model (Val Loss = 0.003896)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  32 | Train Loss: 0.001657 | Val Loss: 0.003925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  33 | Train Loss: 0.001667 | Val Loss: 0.004068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  34 | Train Loss: 0.001541 | Val Loss: 0.003752\n",
            " → New best model (Val Loss = 0.003752)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  35 | Train Loss: 0.001551 | Val Loss: 0.004059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  36 | Train Loss: 0.001516 | Val Loss: 0.003757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  37 | Train Loss: 0.001442 | Val Loss: 0.003764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  38 | Train Loss: 0.001338 | Val Loss: 0.003774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  39 | Train Loss: 0.001372 | Val Loss: 0.003700\n",
            " → New best model (Val Loss = 0.003700)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  40 | Train Loss: 0.001268 | Val Loss: 0.003715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  41 | Train Loss: 0.001244 | Val Loss: 0.003624\n",
            " → New best model (Val Loss = 0.003624)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  42 | Train Loss: 0.001196 | Val Loss: 0.003670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  43 | Train Loss: 0.001157 | Val Loss: 0.003639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  44 | Train Loss: 0.001148 | Val Loss: 0.003872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  45 | Train Loss: 0.001113 | Val Loss: 0.003608\n",
            " → New best model (Val Loss = 0.003608)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  46 | Train Loss: 0.001093 | Val Loss: 0.003770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  47 | Train Loss: 0.001113 | Val Loss: 0.003616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  48 | Train Loss: 0.001183 | Val Loss: 0.003536\n",
            " → New best model (Val Loss = 0.003536)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  49 | Train Loss: 0.001070 | Val Loss: 0.003579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  50 | Train Loss: 0.001019 | Val Loss: 0.003498\n",
            " → New best model (Val Loss = 0.003498)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  51 | Train Loss: 0.000982 | Val Loss: 0.003756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  52 | Train Loss: 0.000973 | Val Loss: 0.003495\n",
            " → New best model (Val Loss = 0.003495)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  53 | Train Loss: 0.000972 | Val Loss: 0.003535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  54 | Train Loss: 0.000987 | Val Loss: 0.003579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  55 | Train Loss: 0.000901 | Val Loss: 0.003510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  56 | Train Loss: 0.000971 | Val Loss: 0.003431\n",
            " → New best model (Val Loss = 0.003431)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  57 | Train Loss: 0.000914 | Val Loss: 0.003481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  58 | Train Loss: 0.000890 | Val Loss: 0.003497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  59 | Train Loss: 0.000870 | Val Loss: 0.003446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  60 | Train Loss: 0.000828 | Val Loss: 0.003393\n",
            " → New best model (Val Loss = 0.003393)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  61 | Train Loss: 0.000850 | Val Loss: 0.003491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  62 | Train Loss: 0.000824 | Val Loss: 0.003588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  63 | Train Loss: 0.000856 | Val Loss: 0.003451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  64 | Train Loss: 0.000813 | Val Loss: 0.003454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  65 | Train Loss: 0.000797 | Val Loss: 0.003413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  66 | Train Loss: 0.000781 | Val Loss: 0.003409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  67 | Train Loss: 0.000760 | Val Loss: 0.003329\n",
            " → New best model (Val Loss = 0.003329)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  68 | Train Loss: 0.000748 | Val Loss: 0.003455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  69 | Train Loss: 0.000730 | Val Loss: 0.003502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  70 | Train Loss: 0.000752 | Val Loss: 0.003367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  71 | Train Loss: 0.000716 | Val Loss: 0.003374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  72 | Train Loss: 0.000707 | Val Loss: 0.003481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  73 | Train Loss: 0.000692 | Val Loss: 0.003384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  74 | Train Loss: 0.000675 | Val Loss: 0.003372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  75 | Train Loss: 0.000661 | Val Loss: 0.003425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  76 | Train Loss: 0.000656 | Val Loss: 0.003430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  77 | Train Loss: 0.000652 | Val Loss: 0.003292\n",
            " → New best model (Val Loss = 0.003292)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  78 | Train Loss: 0.000644 | Val Loss: 0.003408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  79 | Train Loss: 0.000654 | Val Loss: 0.003545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  80 | Train Loss: 0.000656 | Val Loss: 0.003659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  81 | Train Loss: 0.000666 | Val Loss: 0.003617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  82 | Train Loss: 0.000642 | Val Loss: 0.003418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  83 | Train Loss: 0.000649 | Val Loss: 0.003446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  84 | Train Loss: 0.000632 | Val Loss: 0.003455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  85 | Train Loss: 0.000599 | Val Loss: 0.003310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  86 | Train Loss: 0.000594 | Val Loss: 0.003312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  87 | Train Loss: 0.000578 | Val Loss: 0.003452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  88 | Train Loss: 0.000587 | Val Loss: 0.003431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  89 | Train Loss: 0.000590 | Val Loss: 0.003327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  90 | Train Loss: 0.000572 | Val Loss: 0.003367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  91 | Train Loss: 0.000559 | Val Loss: 0.003316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  92 | Train Loss: 0.000535 | Val Loss: 0.003380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  93 | Train Loss: 0.000528 | Val Loss: 0.003239\n",
            " → New best model (Val Loss = 0.003239)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  94 | Train Loss: 0.000537 | Val Loss: 0.003348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  95 | Train Loss: 0.000533 | Val Loss: 0.003311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  96 | Train Loss: 0.000617 | Val Loss: 0.003514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  97 | Train Loss: 0.000665 | Val Loss: 0.003368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  98 | Train Loss: 0.000597 | Val Loss: 0.003431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  99 | Train Loss: 0.000523 | Val Loss: 0.003324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100 | Train Loss: 0.000500 | Val Loss: 0.003383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Results"
      ],
      "metadata": {
        "id": "0PNcJby5c4iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_and_plot(x_raw, y_raw, model, title, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    x_raw, y_raw: torch.Tensor shape [16,16]\n",
        "    model: CPU model that maps x → y directly in spatial domain\n",
        "    \"\"\"\n",
        "    # 1) Add batch and channel dimensions\n",
        "    x = x_raw.unsqueeze(0).unsqueeze(0).to(device)  # [1,1,16,16]\n",
        "    y = y_raw.unsqueeze(0).unsqueeze(0).to(device)  # [1,1,16,16]\n",
        "\n",
        "    # 2) Run model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(x)  # shape: [1,1,16,16]\n",
        "\n",
        "    # 3) Remove batch and channel dims\n",
        "    x = x.squeeze().cpu()       # [16,16]\n",
        "    y = y.squeeze().cpu()       # [16,16]\n",
        "    y_pred = y_pred.squeeze().cpu()  # [16,16]\n",
        "\n",
        "    # 4) Plot\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    axs[0].imshow(x.numpy(), cmap='viridis'); axs[0].set_title(f\"{title}: input x\")\n",
        "    axs[1].imshow(y.numpy(), cmap='viridis'); axs[1].set_title(f\"{title}: true y\")\n",
        "    axs[2].imshow(y_pred.numpy(), cmap='viridis'); axs[2].set_title(f\"{title}: predicted y\")\n",
        "    for ax in axs: ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Mqs_IDQlZ5g7"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick random train index\n",
        "idx_train = random.randrange(x_all.shape[0])\n",
        "run_and_plot(x_all[idx_train], y_all[idx_train], best_model, f\"Train idx={idx_train}\")\n",
        "\n",
        "# Pick random test index\n",
        "idx_test = random.randrange(x_all_test.shape[0])\n",
        "run_and_plot(x_all_test[idx_test], y_all_test[idx_test], best_model, f\"Test idx={idx_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "XkLLYRV_cq77",
        "outputId": "c858b26e-b769-4dd7-cd8e-ef1f54738a00"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8JgUcd7qc9YQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}