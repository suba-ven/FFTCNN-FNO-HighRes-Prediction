{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be25a19d-28eb-46a5-bc3e-3f9f5c05e078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neuraloperator\n",
      "  Using cached neuraloperator-1.0.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting wandb (from neuraloperator)\n",
      "  Using cached wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: ruamel-yaml in /srv/conda/envs/notebook/lib/python3.12/site-packages (from neuraloperator) (0.17.17)\n",
      "Collecting configmypy (from neuraloperator)\n",
      "  Using cached configmypy-0.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting tensorly (from neuraloperator)\n",
      "  Using cached tensorly-0.9.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting tensorly-torch (from neuraloperator)\n",
      "  Using cached tensorly_torch-0.5.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting torch-harmonics==0.7.3 (from neuraloperator)\n",
      "  Using cached torch_harmonics-0.7.3-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib in /srv/conda/envs/notebook/lib/python3.12/site-packages (from neuraloperator) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.25 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from neuraloperator) (2.0.2)\n",
      "Collecting opt-einsum (from neuraloperator)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: h5py in /srv/conda/envs/notebook/lib/python3.12/site-packages (from neuraloperator) (3.12.1)\n",
      "Requirement already satisfied: zarr in /srv/conda/envs/notebook/lib/python3.12/site-packages (from neuraloperator) (3.0.1)\n",
      "Requirement already satisfied: torch>=2.4.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch-harmonics==0.7.3->neuraloperator) (2.5.1.post303)\n",
      "Collecting pytest (from configmypy->neuraloperator)\n",
      "  Using cached pytest-8.3.5-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pytest-mock (from configmypy->neuraloperator)\n",
      "  Using cached pytest_mock-3.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib->neuraloperator) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib->neuraloperator) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib->neuraloperator) (4.55.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib->neuraloperator) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib->neuraloperator) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib->neuraloperator) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib->neuraloperator) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from matplotlib->neuraloperator) (2.9.0)\n",
      "Requirement already satisfied: scipy in /srv/conda/envs/notebook/lib/python3.12/site-packages (from tensorly->neuraloperator) (1.15.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from wandb->neuraloperator) (8.1.8)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->neuraloperator)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from wandb->neuraloperator) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /srv/conda/envs/notebook/lib/python3.12/site-packages (from wandb->neuraloperator) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from wandb->neuraloperator) (5.28.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from wandb->neuraloperator) (5.9.8)\n",
      "Requirement already satisfied: pydantic<3 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from wandb->neuraloperator) (2.10.5)\n",
      "Requirement already satisfied: pyyaml in /srv/conda/envs/notebook/lib/python3.12/site-packages (from wandb->neuraloperator) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from wandb->neuraloperator) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->neuraloperator)\n",
      "  Using cached sentry_sdk-2.27.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb->neuraloperator)\n",
      "  Using cached setproctitle-1.3.6-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.12/site-packages (from wandb->neuraloperator) (75.8.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from wandb->neuraloperator) (4.12.2)\n",
      "Requirement already satisfied: donfig>=0.8 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from zarr->neuraloperator) (0.8.1.post1)\n",
      "Requirement already satisfied: numcodecs>=0.14 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from numcodecs[crc32c]>=0.14->zarr->neuraloperator) (0.15.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb->neuraloperator) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->neuraloperator) (4.0.12)\n",
      "Requirement already satisfied: deprecated in /srv/conda/envs/notebook/lib/python3.12/site-packages (from numcodecs>=0.14->numcodecs[crc32c]>=0.14->zarr->neuraloperator) (1.2.15)\n",
      "Requirement already satisfied: crc32c>=2.7 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from numcodecs[crc32c]>=0.14->zarr->neuraloperator) (2.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pydantic<3->wandb->neuraloperator) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pydantic<3->wandb->neuraloperator) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (2024.12.14)\n",
      "Requirement already satisfied: filelock in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (3.17.0)\n",
      "Requirement already satisfied: networkx in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (2024.12.0)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (1.13.3)\n",
      "Collecting iniconfig (from pytest->configmypy->neuraloperator)\n",
      "  Using cached iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from pytest->configmypy->neuraloperator) (1.5.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->neuraloperator) (5.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from sympy!=1.13.2,>=1.13.1->torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (1.3.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from deprecated->numcodecs>=0.14->numcodecs[crc32c]>=0.14->zarr->neuraloperator) (1.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from jinja2->torch>=2.4.0->torch-harmonics==0.7.3->neuraloperator) (3.0.2)\n",
      "Using cached neuraloperator-1.0.2-py3-none-any.whl (186 kB)\n",
      "Using cached configmypy-0.2.0-py3-none-any.whl (14 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached tensorly-0.9.0-py3-none-any.whl (7.4 MB)\n",
      "Using cached tensorly_torch-0.5.0-py3-none-any.whl (59 kB)\n",
      "Using cached wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached sentry_sdk-2.27.0-py2.py3-none-any.whl (340 kB)\n",
      "Using cached pytest-8.3.5-py3-none-any.whl (343 kB)\n",
      "Using cached pytest_mock-3.14.0-py3-none-any.whl (9.9 kB)\n",
      "Using cached setproctitle-1.3.6-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Using cached iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
      "Installing collected packages: setproctitle, sentry-sdk, opt-einsum, iniconfig, docker-pycreds, tensorly-torch, tensorly, pytest, wandb, torch-harmonics, pytest-mock, configmypy, neuraloperator\n",
      "Successfully installed configmypy-0.2.0 docker-pycreds-0.4.0 iniconfig-2.1.0 neuraloperator-1.0.2 opt-einsum-3.4.0 pytest-8.3.5 pytest-mock-3.14.0 sentry-sdk-2.27.0 setproctitle-1.3.6 tensorly-0.9.0 tensorly-torch-0.5.0 torch-harmonics-0.7.3 wandb-0.19.11\n"
     ]
    }
   ],
   "source": [
    "! pip install neuraloperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce7e91a-0d9b-440f-8340-f6ff5b332288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralop.data.datasets import DarcyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "663e7eb0-5dfa-46ae-b018-891047559762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test db for resolution 16 with 1000 samples \n",
      "Loading test db for resolution 32 with 500 samples \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/neuralop/data/datasets/pt_dataset.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/neuralop/data/datasets/pt_dataset.py:172: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(Path(root_dir).joinpath(f\"{dataset_name}_test_{res}.pt\").as_posix())\n"
     ]
    }
   ],
   "source": [
    "ds = DarcyDataset(root_dir=\"./data\", n_train= 5000, n_tests= [1000, 500],\n",
    "                 batch_size = 32, test_batch_sizes = [32, 32],\n",
    "                 train_resolution= 16,\n",
    "                 test_resolutions =[16,32],download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e68ddc4-e50d-405c-8de1-b05368e461a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = DarcyDataset(root_dir=\"./data\", n_train= 1000, n_tests= [100, 50],\n",
    "                 batch_size = 32, test_batch_sizes = [32, 32],\n",
    "                 train_resolution= 32,\n",
    "                 test_resolutions =[16,32],download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6836540-c3a8-460d-a2fe-284bc3dc88df",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ds.train_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d6f0a40-be7b-4150-aad5-1701017da75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 16, 16])\n",
      "torch.Size([50, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "b = ds.test_dbs[16]\n",
    "full_loader = DataLoader(b,\n",
    "                         batch_size=len(b),\n",
    "                         shuffle=False,\n",
    "                         drop_last=False)\n",
    "\n",
    "batch = next(iter(full_loader))\n",
    "# batch is a dict, so:\n",
    "x_all_test = batch['x']        # shape [1000, 1, 16, 16]\n",
    "y_all_test = batch['y']\n",
    "x_all_test = x_all_test.squeeze(1)  # → [1000, 16, 16]\n",
    "y_all_test = y_all_test.squeeze(1)\n",
    "print(x_all_test.shape)        # should print: torch.Size([1000, 16, 16])\n",
    "print(y_all_test.shape)        # should print: torch.Size([1000, 16, 16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fa3b82b-efd7-455d-b4b2-963ba1cf1340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pair(x_all_test, y_all_test, idx=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77f7bfb5-7950-4794-8b8f-114f917459db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 16, 16])\n",
      "torch.Size([1000, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# a = ds.train_db\n",
    "full_loader = DataLoader(a,\n",
    "                         batch_size=len(a),\n",
    "                         shuffle=False,\n",
    "                         drop_last=False)\n",
    "\n",
    "batch = next(iter(full_loader))\n",
    "# batch is a dict, so:\n",
    "x_all = batch['x']        # shape [1000, 1, 16, 16]\n",
    "y_all = batch['y']\n",
    "x_all = x_all.squeeze(1)  # → [1000, 16, 16]\n",
    "y_all = y_all.squeeze(1)\n",
    "print(x_all.shape)        # should print: torch.Size([1000, 16, 16])\n",
    "print(y_all.shape)        # should print: torch.Size([1000, 16, 16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1adf0b51-e4df-43f2-b565-b401d3e26301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_pair(x_all, y_all, idx):\n",
    "    \"\"\"\n",
    "    Plot x_all[idx] and y_all[idx] side by side.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_all : torch.Tensor or np.ndarray, shape (N, 16, 16)\n",
    "    y_all : torch.Tensor or np.ndarray, shape (N, 16, 16)\n",
    "    idx   : int, which sample to plot\n",
    "\n",
    "    Displays a matplotlib figure.\n",
    "    \"\"\"\n",
    "    # if torch.Tensor, convert to numpy\n",
    "    if hasattr(x_all, 'cpu'):\n",
    "        x = x_all[idx].cpu().numpy()\n",
    "    else:\n",
    "        x = x_all[idx]\n",
    "    if hasattr(y_all, 'cpu'):\n",
    "        y = y_all[idx].cpu().numpy()\n",
    "    else:\n",
    "        y = y_all[idx]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    axes[0].imshow(x, aspect='equal')\n",
    "    axes[0].set_title(f'x_all[{idx}]')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(y, aspect='equal')\n",
    "    axes[1].set_title(f'y_all[{idx}]')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61bf4d45-3a2b-4764-847d-bc0da58df12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07ab3945-4562-4644-a813-574eb4794874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pair(x_all, y_all, idx=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d256d7e2-a019-47ef-b9f4-4598c061eda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pair(x_all, y_all, idx=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f17093-948f-470a-a9c3-28e9449a7169",
   "metadata": {},
   "source": [
    "# creating new fft dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e883640-6e70-40a1-9a28-291bff2d0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def fft_transform(\n",
    "    x: torch.Tensor,\n",
    "    target_size=(256,256),\n",
    "    mode='mag_phase',\n",
    "    eps=1e-6\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a batch of 2D fields to a 2‑channel frequency‐domain tensor.\n",
    "    \n",
    "    Args:\n",
    "      x             Tensor, shape (B, 1, H, W), values in {0,1} or floats.\n",
    "      target_size   (h, w) to interpolate to before FFT.\n",
    "      mode          'mag_phase' or 'real_imag'\n",
    "      eps           small constant to avoid log(0)\n",
    "    \n",
    "    Returns:\n",
    "      Tensor of shape (B, 2, h, w):\n",
    "        * if mode=='mag_phase':  channels = [normalized log|FFT|,  phase/π]\n",
    "        * if mode=='real_imag':  channels = [real(FFT)/M,  imag(FFT)/M]\n",
    "          where M = global max absolute value in batch so both in [–1,1]\n",
    "    \"\"\"\n",
    "    B, C, H, W = x.shape\n",
    "    assert C == 1, \"expect single‐channel input\"\n",
    "    # 1) Upsample spatially (optional; skip if H,W already target_size)\n",
    "    x_up = F.interpolate(x, size=target_size, mode='bilinear', align_corners=False)\n",
    "    # remove channel for FFT: now (B, h, w)\n",
    "    x2 = x_up[:, 0]\n",
    "\n",
    "    # 2) 2D FFT → complex tensor (B, h, w)\n",
    "    Xf = torch.fft.fft2(x2)\n",
    "\n",
    "    if mode == 'mag_phase':\n",
    "        # 3a) magnitude and phase\n",
    "        mag = torch.abs(Xf)\n",
    "        # log1p to avoid –inf at zero\n",
    "        logmag = torch.log1p(mag)\n",
    "        phase = torch.angle(Xf)  # in [–π, π]\n",
    "\n",
    "        # 4a) per‐sample normalization to [0, 1]\n",
    "        # you could also compute global min/max across your TRAINING SET once\n",
    "        lm = logmag.view(B, -1).min(dim=1)[0].view(B,1,1)\n",
    "        lM = logmag.view(B, -1).max(dim=1)[0].view(B,1,1)\n",
    "        mag_n = (logmag - lm) / (lM - lm + eps)\n",
    "\n",
    "        phase_n = (phase + torch.pi) / (2*torch.pi)  # [0,1]\n",
    "\n",
    "        out = torch.stack([mag_n, phase_n], dim=1)\n",
    "\n",
    "    else:\n",
    "        # 3b) real & imag\n",
    "        real = Xf.real\n",
    "        imag = Xf.imag\n",
    "        # 4b) normalize by a global constant so values ~ in [–1,1]\n",
    "        M = torch.max(torch.cat([real.abs(), imag.abs()], dim=0))\n",
    "        out = torch.stack([real/M, imag/M], dim=1)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f3ff7ec-7297-48f1-b9c9-1f2b65833d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FreqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wraps x_all, y_all of shape [N, 16, 16] → returns\n",
    "    (x_fft, y_fft) each of shape [2, 16, 16].\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 x_all: torch.Tensor,   # [N, 16, 16]\n",
    "                 y_all: torch.Tensor,   # [N, 16, 16]\n",
    "                 target_size=(16,16),   # keep 16×16\n",
    "                 mode='mag_phase'):\n",
    "        assert x_all.shape == y_all.shape, \"x and y must match\"\n",
    "        self.x = x_all.unsqueeze(1).float()  # → [N,1,16,16]\n",
    "        self.y = y_all.unsqueeze(1).float()\n",
    "        self.target_size = target_size\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx:idx+1]  # [1,1,16,16]\n",
    "        y = self.y[idx:idx+1]\n",
    "\n",
    "        # apply the FFT‐based transform you defined\n",
    "        x_fft = fft_transform(x,\n",
    "                              target_size=self.target_size,\n",
    "                              mode=self.mode)\n",
    "        y_fft = fft_transform(y,\n",
    "                              target_size=self.target_size,\n",
    "                              mode=self.mode)\n",
    "        # each is [1,2,16,16]; drop the sample dim\n",
    "        return x_fft.squeeze(0), y_fft.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "675b63c1-8381-469f-9a99-44d784643a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 16, 16]) torch.Size([32, 2, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# say x_all,y_all are torch.Tensor of shape [1000,16,16]\n",
    "dataset = FreqDataset(x_all, y_all,\n",
    "                      target_size=(16,16),\n",
    "                      mode='mag_phase')\n",
    "\n",
    "loader = DataLoader(dataset,\n",
    "                    batch_size=32,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True)\n",
    "\n",
    "# check one batch\n",
    "xb, yb = next(iter(loader))\n",
    "print(xb.shape, yb.shape)  # -> [32,2,16,16]  [32,2,16,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41530342-f071-46b0-8de9-6deb736c9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Conv8Net(nn.Module):\n",
    "    def __init__(self, in_ch=2, out_ch=2, max_ch=128):\n",
    "        super().__init__()\n",
    "        # channel progression: 2→32→64→128→64→32→16→2\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch,   32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(  32,   64, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(  64,  128, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d( 128,   64, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(  64,   64, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(  64,   32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(  32,   16, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(  16, out_ch, kernel_size=3, padding=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B,2,H,W]\n",
    "        returns: [B,2,H,W]\n",
    "        \"\"\"\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca3ae131-bd6d-4b37-816d-f01fe8ddcf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_freq_model(model: nn.Module,\n",
    "                     dataset: torch.utils.data.Dataset,\n",
    "                     num_epochs: int = 50,\n",
    "                     batch_size: int = 32,\n",
    "                     lr: float = 1e-3,\n",
    "                     val_split: float = 0.1,\n",
    "                     device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    # Split train/val\n",
    "    N = len(dataset)\n",
    "    n_val = int(N * val_split)\n",
    "    n_train = N - n_val\n",
    "    train_ds, val_ds = random_split(dataset, [n_train, n_val])\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_val = float('inf')\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        # ——— Training ———\n",
    "        model.train()\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs} [Train]\", leave=False)\n",
    "        train_loss = 0.0\n",
    "        for i, (x_fft, y_fft) in enumerate(train_bar):\n",
    "            x_fft, y_fft = x_fft.to(device), y_fft.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_fft)\n",
    "            loss = criterion(y_pred, y_fft)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            avg_train = train_loss / (i + 1)\n",
    "            train_bar.set_postfix(loss=f\"{avg_train:.4f}\")\n",
    "\n",
    "        # ——— Validation ———\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_fft, y_fft in val_loader:\n",
    "                x_fft, y_fft = x_fft.to(device), y_fft.to(device)\n",
    "                y_pred = model(x_fft)\n",
    "                val_loss += criterion(y_pred, y_fft).item()\n",
    "        avg_val = val_loss / max(len(val_loader), 1)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{num_epochs}  \"\n",
    "            f\"Train Loss={train_loss/len(train_loader):.6f}  \"\n",
    "            f\"Val   Loss={avg_val:.6f}\"\n",
    "        )\n",
    "\n",
    "        if avg_val < best_val:\n",
    "            best_val = avg_val\n",
    "            best_state = model.state_dict()\n",
    "            print(f\" → New best model (Val Loss={best_val:.6f})\")\n",
    "\n",
    "    # load best weights & return on CPU\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model.to(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a9d1850-590e-47bf-8cc6-a51eb9c32ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100  Train Loss=0.119335  Val   Loss=0.070400\n",
      " → New best model (Val Loss=0.070400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100  Train Loss=0.059052  Val   Loss=0.050967\n",
      " → New best model (Val Loss=0.050967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100  Train Loss=0.045218  Val   Loss=0.042637\n",
      " → New best model (Val Loss=0.042637)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100  Train Loss=0.040812  Val   Loss=0.040249\n",
      " → New best model (Val Loss=0.040249)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100  Train Loss=0.038959  Val   Loss=0.038759\n",
      " → New best model (Val Loss=0.038759)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100  Train Loss=0.037920  Val   Loss=0.038095\n",
      " → New best model (Val Loss=0.038095)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100  Train Loss=0.037473  Val   Loss=0.037778\n",
      " → New best model (Val Loss=0.037778)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100  Train Loss=0.037275  Val   Loss=0.037633\n",
      " → New best model (Val Loss=0.037633)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100  Train Loss=0.037090  Val   Loss=0.037476\n",
      " → New best model (Val Loss=0.037476)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100  Train Loss=0.036926  Val   Loss=0.037296\n",
      " → New best model (Val Loss=0.037296)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100  Train Loss=0.036819  Val   Loss=0.037159\n",
      " → New best model (Val Loss=0.037159)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100  Train Loss=0.036684  Val   Loss=0.037080\n",
      " → New best model (Val Loss=0.037080)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100  Train Loss=0.036543  Val   Loss=0.036933\n",
      " → New best model (Val Loss=0.036933)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100  Train Loss=0.036465  Val   Loss=0.036871\n",
      " → New best model (Val Loss=0.036871)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100  Train Loss=0.036377  Val   Loss=0.036653\n",
      " → New best model (Val Loss=0.036653)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100  Train Loss=0.036287  Val   Loss=0.036635\n",
      " → New best model (Val Loss=0.036635)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100  Train Loss=0.036245  Val   Loss=0.036646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100  Train Loss=0.036198  Val   Loss=0.036647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100  Train Loss=0.036184  Val   Loss=0.036594\n",
      " → New best model (Val Loss=0.036594)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100  Train Loss=0.036071  Val   Loss=0.036466\n",
      " → New best model (Val Loss=0.036466)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100  Train Loss=0.036037  Val   Loss=0.036444\n",
      " → New best model (Val Loss=0.036444)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100  Train Loss=0.035990  Val   Loss=0.036512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100  Train Loss=0.035967  Val   Loss=0.036392\n",
      " → New best model (Val Loss=0.036392)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100  Train Loss=0.035918  Val   Loss=0.036334\n",
      " → New best model (Val Loss=0.036334)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100  Train Loss=0.035902  Val   Loss=0.036295\n",
      " → New best model (Val Loss=0.036295)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100  Train Loss=0.035850  Val   Loss=0.036293\n",
      " → New best model (Val Loss=0.036293)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100  Train Loss=0.035820  Val   Loss=0.036308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100  Train Loss=0.035761  Val   Loss=0.036281\n",
      " → New best model (Val Loss=0.036281)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100  Train Loss=0.035757  Val   Loss=0.036271\n",
      " → New best model (Val Loss=0.036271)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100  Train Loss=0.035728  Val   Loss=0.036360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100  Train Loss=0.035703  Val   Loss=0.036208\n",
      " → New best model (Val Loss=0.036208)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100  Train Loss=0.035610  Val   Loss=0.036173\n",
      " → New best model (Val Loss=0.036173)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100  Train Loss=0.035554  Val   Loss=0.036162\n",
      " → New best model (Val Loss=0.036162)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100  Train Loss=0.035510  Val   Loss=0.036186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100  Train Loss=0.035470  Val   Loss=0.036138\n",
      " → New best model (Val Loss=0.036138)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100  Train Loss=0.035358  Val   Loss=0.035982\n",
      " → New best model (Val Loss=0.035982)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100  Train Loss=0.035326  Val   Loss=0.036063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100  Train Loss=0.035338  Val   Loss=0.036143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100  Train Loss=0.035243  Val   Loss=0.035973\n",
      " → New best model (Val Loss=0.035973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100  Train Loss=0.035159  Val   Loss=0.035939\n",
      " → New best model (Val Loss=0.035939)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100  Train Loss=0.035096  Val   Loss=0.035979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100  Train Loss=0.035023  Val   Loss=0.035881\n",
      " → New best model (Val Loss=0.035881)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100  Train Loss=0.034981  Val   Loss=0.036157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100  Train Loss=0.034893  Val   Loss=0.035967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100  Train Loss=0.034813  Val   Loss=0.035845\n",
      " → New best model (Val Loss=0.035845)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100  Train Loss=0.034781  Val   Loss=0.035962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100  Train Loss=0.034687  Val   Loss=0.035738\n",
      " → New best model (Val Loss=0.035738)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100  Train Loss=0.034644  Val   Loss=0.035689\n",
      " → New best model (Val Loss=0.035689)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100  Train Loss=0.034540  Val   Loss=0.035596\n",
      " → New best model (Val Loss=0.035596)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100  Train Loss=0.034420  Val   Loss=0.035642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100  Train Loss=0.034425  Val   Loss=0.035737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100  Train Loss=0.034281  Val   Loss=0.035682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100  Train Loss=0.034234  Val   Loss=0.035600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100  Train Loss=0.034118  Val   Loss=0.035669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100  Train Loss=0.034059  Val   Loss=0.035740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100  Train Loss=0.033981  Val   Loss=0.035635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100  Train Loss=0.033942  Val   Loss=0.035521\n",
      " → New best model (Val Loss=0.035521)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100  Train Loss=0.033808  Val   Loss=0.035673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100  Train Loss=0.033796  Val   Loss=0.035730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100  Train Loss=0.033667  Val   Loss=0.035379\n",
      " → New best model (Val Loss=0.035379)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100  Train Loss=0.033542  Val   Loss=0.035411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100  Train Loss=0.033450  Val   Loss=0.035566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100  Train Loss=0.033379  Val   Loss=0.035201\n",
      " → New best model (Val Loss=0.035201)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100  Train Loss=0.033277  Val   Loss=0.035292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100  Train Loss=0.033192  Val   Loss=0.035219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100  Train Loss=0.033125  Val   Loss=0.035228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100  Train Loss=0.033033  Val   Loss=0.035346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100  Train Loss=0.032979  Val   Loss=0.035189\n",
      " → New best model (Val Loss=0.035189)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100  Train Loss=0.032884  Val   Loss=0.035183\n",
      " → New best model (Val Loss=0.035183)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100  Train Loss=0.032776  Val   Loss=0.035176\n",
      " → New best model (Val Loss=0.035176)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100  Train Loss=0.032771  Val   Loss=0.035430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100  Train Loss=0.032653  Val   Loss=0.035323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100  Train Loss=0.032499  Val   Loss=0.035446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100  Train Loss=0.032443  Val   Loss=0.035245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100  Train Loss=0.032261  Val   Loss=0.035424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100  Train Loss=0.032231  Val   Loss=0.035097\n",
      " → New best model (Val Loss=0.035097)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100  Train Loss=0.032108  Val   Loss=0.035382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100  Train Loss=0.032101  Val   Loss=0.035185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100  Train Loss=0.031894  Val   Loss=0.035386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100  Train Loss=0.031808  Val   Loss=0.035540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100  Train Loss=0.031691  Val   Loss=0.035595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100  Train Loss=0.031724  Val   Loss=0.035481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100  Train Loss=0.031535  Val   Loss=0.035502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100  Train Loss=0.031460  Val   Loss=0.035663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100  Train Loss=0.031401  Val   Loss=0.035654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100  Train Loss=0.031239  Val   Loss=0.035827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100  Train Loss=0.031143  Val   Loss=0.035915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100  Train Loss=0.031147  Val   Loss=0.036049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100  Train Loss=0.031060  Val   Loss=0.036019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100  Train Loss=0.030997  Val   Loss=0.035949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100  Train Loss=0.030851  Val   Loss=0.035672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100  Train Loss=0.030695  Val   Loss=0.036049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100  Train Loss=0.030699  Val   Loss=0.036217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100  Train Loss=0.030625  Val   Loss=0.035868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100  Train Loss=0.030341  Val   Loss=0.036191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100  Train Loss=0.030263  Val   Loss=0.036422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100  Train Loss=0.030161  Val   Loss=0.036509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100  Train Loss=0.030232  Val   Loss=0.036405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100  Train Loss=0.030014  Val   Loss=0.036333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100  Train Loss=0.029908  Val   Loss=0.036367\n"
     ]
    }
   ],
   "source": [
    "model   = Conv8Net(in_ch=2, out_ch=2)\n",
    "\n",
    "best_model = train_freq_model(\n",
    "    model,\n",
    "    dataset,\n",
    "    num_epochs=100,\n",
    "    batch_size=32,\n",
    "    lr=1e-3,\n",
    "    val_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d080331c-8e04-4d2a-9cbd-64b95feaf6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "def run_and_plot(x_raw, y_raw, model, title):\n",
    "    \"\"\"\n",
    "    x_raw, y_raw: torch.Tensor shape [16,16]\n",
    "    model: CPU model that maps fft→fft\n",
    "    \"\"\"\n",
    "    # 1) Prepare batch dims & channels\n",
    "    x = x_raw.unsqueeze(0).unsqueeze(0)  # [1,1,16,16]\n",
    "    y = y_raw.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # 2) FFT‐transform\n",
    "    x_fft = fft_transform(x, target_size=(16,16), mode='mag_phase')  # [1,2,16,16]\n",
    "    # 3) Predict in freq‐domain\n",
    "    with torch.no_grad():\n",
    "        y_pred_fft = model(x_fft)  # [1,2,16,16]\n",
    "    y_pred_fft = y_pred_fft.squeeze(0)\n",
    "    print(y_pred_fft.shape)\n",
    "    # 4) Inverse‐transform\n",
    "    y_rec = inverse_fft_transform(y_pred_fft, y_raw)  # [1,16,16]\n",
    "    y_rec = y_rec.squeeze(0)                   # [16,16]\n",
    "\n",
    "    # 5) Plot\n",
    "    fig, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "    axs[0].imshow(x_raw.numpy(), cmap='viridis'); axs[0].set_title(f\"{title}: input x\")\n",
    "    axs[1].imshow(y_raw.numpy(), cmap='viridis'); axs[1].set_title(f\"{title}: true y\")\n",
    "    axs[2].imshow(y_rec.numpy(), cmap='viridis'); axs[2].set_title(f\"{title}: recon y\")\n",
    "    for ax in axs: ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "805cfb9d-034b-4130-af67-123c7fed1531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def inverse_fft_transform(norm_fft: torch.Tensor,\n",
    "                          raw: torch.Tensor,\n",
    "                          eps: float = 1e-8) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Invert the mag–phase normalization back to a real image.\n",
    "\n",
    "    Args:\n",
    "      norm_fft:    Tensor of shape [2, H, W], channels = [norm_log_mag, norm_phase]\n",
    "      raw:         Tensor of shape [H, W] (the original spatial image)\n",
    "      eps:         small constant\n",
    "\n",
    "    Returns:\n",
    "      recov:       Tensor of shape [H, W], the reconstructed real‐space field\n",
    "    \"\"\"\n",
    "    # 1) Recompute L_min, L_max on the original\n",
    "    Xf_orig = torch.fft.fft2(raw)\n",
    "    mag_orig = torch.abs(Xf_orig)\n",
    "    logmag   = torch.log(mag_orig + eps)\n",
    "    L_min    = logmag.min()\n",
    "    L_max    = logmag.max()\n",
    "\n",
    "    # 2) Split the two channels\n",
    "    norm_log_mag = norm_fft[0]   # shape [H,W]\n",
    "    norm_phase   = norm_fft[1]   # shape [H,W]\n",
    "\n",
    "    # 3) Reverse normalization on log-magnitude\n",
    "    recov_log_mag = norm_log_mag * (L_max - L_min) + L_min\n",
    "    recov_mag     = torch.exp(recov_log_mag) - eps\n",
    "\n",
    "    # 4) Reverse normalization on phase\n",
    "    recov_phase   = norm_phase * (2 * torch.pi) - torch.pi\n",
    "\n",
    "    # 5) Reconstruct complex spectrum and IFFT\n",
    "    real_part = recov_mag * torch.cos(recov_phase)\n",
    "    imag_part = recov_mag * torch.sin(recov_phase)\n",
    "    Xf_rec    = torch.complex(real_part, imag_part)\n",
    "    recov     = torch.fft.ifft2(Xf_rec).real\n",
    "\n",
    "    return recov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a186e884-8309-4fe0-a9b7-dd2506364830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 16])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 16])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pick random train index\n",
    "idx_train = random.randrange(x_all.shape[0])\n",
    "run_and_plot(x_all[idx_train], y_all[idx_train], best_model, f\"Train idx={idx_train}\")\n",
    "\n",
    "# Pick random test index\n",
    "idx_test = random.randrange(x_all_test.shape[0])\n",
    "run_and_plot(x_all_test[idx_test], y_all_test[idx_test], best_model, f\"Test idx={idx_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c77ee1-9ab8-4ac2-a3e3-c617427d2a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
